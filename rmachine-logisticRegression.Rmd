---
title: "Logistic Regression In R"
output: html_document
---

&nbsp;

Hi. This page is on using the R programming language for doing logistic regression. In regular linear regression, the response variable is a numeric variable while the response variable in logistic regression is a binary variable. 

References include the Udemy Course - R For Data Science & Machine Learning By Jose Portilla and the Introduction To Statistical Learning With R Book. 

The packages that are used in R are `ISLR`, `ggplot2` and `caTools`. From the `ISLR` library, the Default dataset is used. This default data looks at credit card defaults. The response variable here is the default variable which is either Yes or No.

&nbsp;

```{r}
# Logistic Regression In R

# Reference: Udemy Course - R For Data Science & Machine Learning By Jose Portilla

# Book & Library Reference: Introduction To Statistical Learning With R
# Book Info Link:https://www-bcf.usc.edu/~gareth/ISL/ 

library(ISLR)
library(ggplot2)

default_data <- Default

# Preview the data:

head(default_data)

tail(default_data)

str(default_data)
```

&nbsp;

From the `head()`, `tail()` and `str()` outputs, we see that there are four columns/variables and 10000 observations. The response variable of interest is the default variable. Credit card defaults are either Yes or No. 

With the `table()` function, counts on the default column can be retrieved.

&nbsp;

```{r}
# Check default column on counts
table(default_data$default)
```

&nbsp;

For a visual of the counts, a barplot can be generated with the use of R's `ggplot2` graphics.

&nbsp;

```{r, echo = TRUE, fig.width=4, fig.height=4}
# Initial Barplot (No Labels):

ggplot(default_data, aes(x = default)) +
  geom_bar() +
  labs(x = "\n Credit Default Status", y = "Count\n", 
       title = "Credit Default Status Of Customers \n") +
  theme(plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(face="bold", colour="darkgreen", size = 12),
        axis.title.y = element_text(face="bold", colour="darkgreen", size = 12),
        legend.title = element_text(face="bold", colour="brown", size = 10)) 
```

&nbsp;

When it comes to logistic regression in R, it is not ideal to keep "Yes and "No" in the default column of the dataset. A function is created such that if the default status is "Yes" it gets converted into 1 and if it is a "No" it gets converted into a 0. This function is then used in a `sapply()` function on the default column.

&nbsp;

```{r}
# For logistic regression purposes: change No to 0 and Yes to 1 for default column.

# Combine never-worked and without pay groups into unemployed

default_change <- function(def_status){
  if (def_status== 'Yes'){
    return(1)
  }else{
    return(0)
  }
}

# Use sapply on type_employer column:
# Yes turns into 1 and No turns into 0 for logistic regression.

default_data$default <- sapply(default_data$default, default_change)
```

&nbsp;

The changes can be verified with the use of the `table()` and `str()` functions.

&nbsp;

```{r}
# Check with table() and str() functions.

table(default_data$default)

str(default_data)
```

&nbsp;

To fit a logistic regression model in R, use the `glm()` function with the appropriate formula, family and data. For the family argument, do use `binomial(link = "logit")` for logistic regression. (Using a different link function is for a different regression model such as linear and poisson.)


&nbsp;

```{r}
# Running logistic regression model 
# Use binomial(link = 'logit')

log_model <- glm(formula = default ~ . , family = binomial(link='logit'), data = default_data)

# Run summary of logistic model:

summary(log_model)
```

&nbsp;

This next part looks at creating a training data set and a test set from the credit default data. The logistic regression model is with the training data and the test data is with the `predict()` function.

The `sample.split()` helps in splitting the data into a training set and into a test set.

&nbsp;

```{r}
# ---------------------------------------------------------------------
# Using test cases for predictions, make training data and test data

library(caTools)

set.seed(101)

split = sample.split(default_data$default, SplitRatio = 0.70)

train_data = subset(default_data, split == TRUE)
test_data = subset(default_data, split == FALSE)
```

&nbsp;

The `glm()` function is used again for fitting a logistic regression model. This time the data input is the training data. 

&nbsp;

```{r}
# Running the logistic regression model again:

log_model2 <- glm(formula = default ~ . , family = binomial(link='logit'), data = train_data)

summary(log_model2)
```

&nbsp;

Any testing data is used for predictions. The `predict()` function is associated with the test_data and `type = "response"` is used.

In the `ifelse()` function, if any probabilities is above 0.5 assign a one and anything below 0.5 assign a 0.

&nbsp;

```{r}
# Model Diagnostics

fitted_probs <- predict(log_model2, newdata = test_data, type = 'response')

fitted_results <- ifelse(fitted_probs > 0.5, 1, 0)
```

&nbsp;

The misclassification error is a percentage where the test_data default values (0 or 1) do not match the fitted results. 

Taking one minus the misclassification error gives the accuracy of of the predictions.


&nbsp;


```{r}
# Obtaining the accuracy of predictions:

misClassError <- mean(fitted_results != test_data$default)

print(paste('Accuracy', 1 - misClassError))
```

&nbsp;

A confusion matrix of counts can be displayed in a table format in R with the use of the `table()` function of the default column where the fitted probabilities are above 0.5. Predictions are on the top and the actual outcomes are on the rows.


&nbsp;

```{r}
# Confusion matrix of Counts 
# (Predictions on top FALSE/TRUE, actual as rows):

table(test_data$default, fitted_probs > 0.5)
```

&nbsp;
